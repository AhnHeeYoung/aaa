{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8fac04fa50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import openslide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import memmap\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import logging.handlers\n",
    "torch.manual_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/colon_result_temp', 'rb') as f:\n",
    "    colon_result = pickle.load(f)\n",
    "    \n",
    "with open('result/sigmoid_result_temp', 'rb') as f:\n",
    "    sigmoid_result = pickle.load(f)\n",
    "    \n",
    "with open('result/rectum_result_temp', 'rb') as f:\n",
    "    rectum_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = '-'\n",
    "if not os.path.exists('checkpoint/{}'.format(info)):\n",
    "    os.mkdir('checkpoint/{}'.format(info))\n",
    "    \n",
    "log = logging.getLogger('log')\n",
    "log.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "fileHandler = logging.FileHandler('checkpoint/{}/{}_log.txt'.format(info, info))\n",
    "streamHandler = logging.StreamHandler()\n",
    "fileHandler.setFormatter(formatter)\n",
    "streamHandler.setFormatter(formatter)\n",
    "log.addHandler(fileHandler)\n",
    "log.addHandler(streamHandler)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "data_all = np.concatenate([np.array(colon_result), np.array(sigmoid_result), np.array(rectum_result)])\n",
    "\n",
    "# colon_result, sigmoid_result, rectum_result 안에 있는 모든 패치의 총합 데이터\n",
    "data_final = np.zeros(0)\n",
    "for i in range(len(data_all)):\n",
    "    temp = np.array(data_all[i])\n",
    "    data_final = np.concatenate([data_final, temp])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, long_short=None, transform=False):\n",
    "        self.dataset = dataset\n",
    "        self.long_short = long_short\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        lines = self.dataset[idx]\n",
    "        ID = lines['ID']\n",
    "        image = lines['image']\n",
    "        status = lines['status']\n",
    "        duration = lines['duration']\n",
    "        \n",
    "        image = transforms.ToPILImage()(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        image = transforms.RandomRotation(90)(image)\n",
    "        \n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(image)\n",
    "        \n",
    "        if self.long_short:\n",
    "            long_short = lines['long_short']\n",
    "        return {'ID' : ID ,'image' : image, 'status' : status, 'duration' : duration, 'long_short' : long_short}\n",
    "\n",
    "def create_file(file_path,msg):\n",
    "    msg = msg+'\\n'\n",
    "    f=open(file_path,\"a\")\n",
    "    f.write(msg)\n",
    "    f.close\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# cutoff 기준 데이터 분할\n",
    "output = []\n",
    "for i in range(len(data_final)):\n",
    "    output.append(data_final[i]['status'])\n",
    "output = np.array(output)\n",
    "\n",
    "alive_data = data_final[output==0]\n",
    "dead_data = data_final[output==1]\n",
    "\n",
    "alive_duration = []\n",
    "for i in range(len(alive_data)):\n",
    "    alive_duration.append(alive_data[i]['duration'])\n",
    "alive_duration = np.array(alive_duration)\n",
    "\n",
    "dead_duration = []\n",
    "for i in range(len(dead_data)):\n",
    "    dead_duration.append(dead_data[i]['duration'])\n",
    "dead_duration = np.array(dead_duration)\n",
    "\n",
    "cutoff = 365*5\n",
    "three_up_alive = alive_data[alive_duration>=cutoff]\n",
    "three_up_dead = dead_data[dead_duration>=cutoff]\n",
    "three_down_dead = dead_data[dead_duration<cutoff]\n",
    "\n",
    "Long_live_patient = np.concatenate([three_up_alive, three_up_dead])\n",
    "Short_live_patient = three_down_dead\n",
    "\n",
    "#three_years_all = np.concatenate([three_years_alive, three_years_dead])\n",
    "\n",
    "#three_years_label = []\n",
    "#for i in range(len(three_years_all)):\n",
    "#    three_years_label.append(three_years_all[i]['status'])\n",
    "#three_years_label = np.array(three_years_label)\n",
    "\n",
    "for i in range(len(Long_live_patient)):\n",
    "    Long_live_patient[i].update(long_short = 1)\n",
    "    \n",
    "for i in range(len(Short_live_patient)):\n",
    "    Short_live_patient[i].update(long_short = 0) \n",
    "    \n",
    "prog1 = []\n",
    "for i in range(len(Long_live_patient)):\n",
    "    prog1.append(Long_live_patient[i]['long_short'])\n",
    "prog1 = np.array(prog1)\n",
    "\n",
    "prog2 = []\n",
    "for i in range(len(Short_live_patient)):\n",
    "    prog2.append(Short_live_patient[i]['long_short'])\n",
    "prog2 = np.array(prog2)\n",
    "\n",
    "Long_Short_All = np.concatenate([Long_live_patient, Short_live_patient])\n",
    "prog_All = np.concatenate([prog1, prog2])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "out1 = []\n",
    "out2 = []\n",
    "out3 = []\n",
    "out4 = []\n",
    "for i in range(len(Long_live_patient)):\n",
    "    out1.append(Long_live_patient[i]['ID'][:12])\n",
    "    out2.append(Long_live_patient[i]['ID'])\n",
    "out1 = np.array(out1)\n",
    "out2 = np.array(out2)\n",
    "\n",
    "for i in range(len(Short_live_patient)):\n",
    "    out3.append(Short_live_patient[i]['ID'][:12])\n",
    "    out4.append(Short_live_patient[i]['ID'])\n",
    "out3 = np.array(out3)\n",
    "out4 = np.array(out4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-25 16:54:38,132 - INFO - Long 환자 수 : 20 (36 WSI)\n",
      "2021-01-25 16:54:38,134 - INFO - Short 환자 수 : 41 (79 WSI)\n",
      "2021-01-25 16:54:38,135 - INFO - \n",
      "\n",
      "2021-01-25 16:54:38,139 - INFO - -----  Fold 1  -----\n",
      "2021-01-25 16:54:38,141 - INFO - Train 환자 수 : 40\n",
      "2021-01-25 16:54:38,142 - INFO - Test 환자 수 : 21\n",
      "2021-01-25 16:54:38,143 - INFO - \n",
      "\n",
      "2021-01-25 16:54:38,307 - INFO - Epoch  1\n",
      "2021-01-25 16:54:40,067 - INFO - Epoch : 1/1, Batch : 1/1, Loss : 0.666, ACC : 0.610, AUC : 0.527\n",
      "2021-01-25 16:54:40,133 - INFO - Train Evaluation Result\n",
      "2021-01-25 16:54:40,134 - INFO - Epoch : 1/1, Batch : 1/1, Loss : 0.666, ACC : 0.610, AUC:0.527\n",
      "2021-01-25 16:54:40,145 - INFO - Train_Patient_Level_ACC : 0.525 / Train_Patient_Level_AUC : 0.564\n",
      "2021-01-25 16:54:41,205 - INFO - TEST Evaluation Result\n",
      "2021-01-25 16:54:41,207 - INFO - Epoch : 1/1, Batch : 76/1, Loss : 0.659, ACC : 0.658, AUC : 0.637\n",
      "2021-01-25 16:54:41,267 - INFO - \n",
      "\n",
      "2021-01-25 16:54:41,268 - INFO - ---------------------------------   Test_Patient_Level_Mean_AUC : 0.735\n",
      "2021-01-25 16:54:41,269 - INFO - ---------------------------------  Test_Patient_Level_Max_AUC : 0.735\n",
      "2021-01-25 16:54:41,270 - INFO - ---------------------------------   Test_Patient_Level_Min_AUC : 0.684\n",
      "2021-01-25 16:54:41,271 - INFO - \n",
      "\n",
      "2021-01-25 16:54:41,354 - INFO - -----  Fold 2  -----\n",
      "2021-01-25 16:54:41,357 - INFO - Train 환자 수 : 40\n",
      "2021-01-25 16:54:41,358 - INFO - Test 환자 수 : 21\n",
      "2021-01-25 16:54:41,358 - INFO - \n",
      "\n",
      "2021-01-25 16:54:41,531 - INFO - Epoch  1\n",
      "2021-01-25 16:54:43,049 - INFO - Epoch : 1/1, Batch : 1/1, Loss : 1.180, ACC : 0.333, AUC : 0.501\n",
      "2021-01-25 16:54:43,116 - INFO - Train Evaluation Result\n",
      "2021-01-25 16:54:43,118 - INFO - Epoch : 1/1, Batch : 1/1, Loss : 1.180, ACC : 0.333, AUC:0.501\n",
      "2021-01-25 16:54:43,127 - INFO - Train_Patient_Level_ACC : 0.325 / Train_Patient_Level_AUC : 0.521\n",
      "2021-01-25 16:54:44,323 - INFO - TEST Evaluation Result\n",
      "2021-01-25 16:54:44,325 - INFO - Epoch : 1/1, Batch : 86/1, Loss : 0.787, ACC : 0.279, AUC : 0.549\n",
      "2021-01-25 16:54:44,365 - INFO - \n",
      "\n",
      "2021-01-25 16:54:44,366 - INFO - ---------------------------------   Test_Patient_Level_Mean_AUC : 0.633\n",
      "2021-01-25 16:54:44,367 - INFO - ---------------------------------  Test_Patient_Level_Max_AUC : 0.490\n",
      "2021-01-25 16:54:44,368 - INFO - ---------------------------------   Test_Patient_Level_Min_AUC : 0.622\n",
      "2021-01-25 16:54:44,368 - INFO - \n",
      "\n",
      "2021-01-25 16:54:44,448 - INFO - -----  Fold 3  -----\n",
      "2021-01-25 16:54:44,451 - INFO - Train 환자 수 : 42\n",
      "2021-01-25 16:54:44,452 - INFO - Test 환자 수 : 19\n",
      "2021-01-25 16:54:44,453 - INFO - \n",
      "\n",
      "2021-01-25 16:54:44,634 - INFO - Epoch  1\n",
      "2021-01-25 16:54:46,244 - INFO - Epoch : 1/1, Batch : 1/1, Loss : 0.799, ACC : 0.315, AUC : 0.533\n",
      "2021-01-25 16:54:46,322 - INFO - Train Evaluation Result\n",
      "2021-01-25 16:54:46,323 - INFO - Epoch : 1/1, Batch : 1/1, Loss : 0.799, ACC : 0.315, AUC:0.533\n",
      "2021-01-25 16:54:46,334 - INFO - Train_Patient_Level_ACC : 0.357 / Train_Patient_Level_AUC : 0.635\n",
      "2021-01-25 16:54:47,399 - INFO - TEST Evaluation Result\n",
      "2021-01-25 16:54:47,400 - INFO - Epoch : 1/1, Batch : 68/1, Loss : 0.812, ACC : 0.324, AUC : 0.351\n",
      "2021-01-25 16:54:47,437 - INFO - \n",
      "\n",
      "2021-01-25 16:54:47,438 - INFO - ---------------------------------   Test_Patient_Level_Mean_AUC : 0.244\n",
      "2021-01-25 16:54:47,438 - INFO - ---------------------------------  Test_Patient_Level_Max_AUC : 0.218\n",
      "2021-01-25 16:54:47,439 - INFO - ---------------------------------   Test_Patient_Level_Min_AUC : 0.269\n",
      "2021-01-25 16:54:47,439 - INFO - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "out1_ = np.unique(out1.reshape(out1.shape[0], 1))\n",
    "out3_ = np.unique(out3.reshape(out3.shape[0], 1))\n",
    "\n",
    "kfold_long = KFold(n_splits=3, shuffle=True)\n",
    "kfold_short = KFold(n_splits=3, shuffle=True)\n",
    "kf_long = kfold_long.split(out1_, out1_)\n",
    "kf_short = kfold_short.split(out3_, out3_)\n",
    "\n",
    "X_train_Long = []\n",
    "X_test_Long = []\n",
    "for i, (train_idx, test_idx) in enumerate(kf_long):\n",
    "    train, test = out1_[train_idx], out1_[test_idx]\n",
    "    X_train_Long.append(train)\n",
    "    X_test_Long.append(test)\n",
    "    \n",
    "X_train_Short = []\n",
    "X_test_Short = []    \n",
    "for i, (train_idx, test_idx) in enumerate(kf_short):\n",
    "    train, test = out3_[train_idx], out3_[test_idx]\n",
    "    X_train_Short.append(train)\n",
    "    X_test_Short.append(test)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "temp = []\n",
    "for i in range(len(Long_Short_All)):\n",
    "    temp.append(Long_Short_All[i]['ID'][:12])\n",
    "temp = np.array(temp)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "num_epochs=1\n",
    "\n",
    "log.info(\"Long 환자 수 : {} ({} WSI)\".format(np.unique(out1).shape[0], np.unique(out2).shape[0]))\n",
    "log.info(\"Short 환자 수 : {} ({} WSI)\".format(np.unique(out3).shape[0], np.unique(out4).shape[0]))\n",
    "log.info(\"\\n\")\n",
    "\n",
    "n_fold = 3\n",
    "for fold in range(n_fold):\n",
    "    create_file(f'checkpoint/{info}/result.csv', f'fold{fold+1}')\n",
    "    \n",
    "    \n",
    "    log.info('-----  Fold {}  -----'.format(fold+1))\n",
    "    \n",
    "    train_idx = np.concatenate([X_train_Long[fold], X_train_Short[fold]]).reshape(-1, )\n",
    "    test_idx = np.concatenate([X_test_Long[fold], X_test_Short[fold]]).reshape(-1, )\n",
    "    \n",
    "    temp = []\n",
    "    for i in range(len(Long_Short_All)):\n",
    "        temp.append(Long_Short_All[i]['ID'][:12])\n",
    "    temp = np.array(temp)\n",
    "    \n",
    "    X_train = Long_Short_All[np.isin(temp, train_idx)]\n",
    "    X_test = Long_Short_All[np.isin(temp, test_idx)]\n",
    "    \n",
    "    \n",
    "    train_ID = []\n",
    "    for i in range(len(X_train)):\n",
    "        train_ID.append(X_train[i]['ID'][:12])\n",
    "    train_ID = np.array(train_ID)\n",
    "\n",
    "    test_ID = []\n",
    "    for i in range(len(X_test)):\n",
    "        test_ID.append(X_test[i]['ID'][:12])\n",
    "    test_ID = np.array(test_ID)\n",
    "    \n",
    "    log.info(\"Train 환자 수 : {}\".format(np.unique(train_ID).shape[0]))\n",
    "    log.info(\"Test 환자 수 : {}\".format(np.unique(test_ID).shape[0]))\n",
    "    log.info(\"\\n\")\n",
    "    \n",
    "    transform = transforms.ColorJitter(brightness=0.25,#0.25\n",
    "                                   contrast=0.75,#0.75\n",
    "                                   saturation=0.25,#0.25\n",
    "                                   hue=0.1)\n",
    "    \n",
    "    train_dataset = Dataset(X_train, long_short=True, transform=transform)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=16)\n",
    "\n",
    "    test_dataset = Dataset(X_test, long_short=True, transform=transform)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True, num_workers=16)\n",
    "    \n",
    "    #model = models.resnet18(pretrained=True)\n",
    "    #model.fc = nn.Linear(512, 2)\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Linear(512, 2)   \n",
    "    \n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        log.info('Epoch  {}'.format(epoch+1))\n",
    "        train_loss = []\n",
    "        train_predicted = []\n",
    "        train_label = []\n",
    "        train_pos = []\n",
    "        ID = []\n",
    "        long_short = []\n",
    "        label = []\n",
    "    \n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            output = model(batch['image'].to(device))\n",
    "        \n",
    "            loss = criterion(output, batch['long_short'].to(device))\n",
    "        \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "            loss = loss.cpu().detach().numpy()\n",
    "        \n",
    "            #evaluation result\n",
    "            pred_label = np.argmax(output.cpu().detach().numpy(),1)\n",
    "            pred_prob  = nn.Softmax(1)(output).cpu().detach().numpy()\n",
    "            positive_prob = pred_prob[:, 1].tolist()   # 1이라고 예측한 확률 (True Positive?) -> auc 구하기 위한 코드\n",
    "            \n",
    "            train_label += batch['long_short'].tolist()          ## 1에폭의 785개 배치에 있는 6280개에 대한 true label\n",
    "            train_loss += [loss.tolist()]    \n",
    "            train_predicted += pred_label.tolist()\n",
    "            train_pos += positive_prob\n",
    "            label += pred_label.tolist()\n",
    "            \n",
    "            train_patient = []\n",
    "            for j in range(len(batch['ID'])):\n",
    "                train_patient.append(batch['ID'][j][:12])\n",
    "                \n",
    "            ID += train_patient\n",
    "            long_short += batch['long_short'].tolist()\n",
    "        \n",
    "        \n",
    "            batch_acc = np.sum(np.array(train_label) == np.array(train_predicted))/ len(train_label) \n",
    "            batch_mean_loss = sum(train_loss)/len(train_loss)\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(train_label, train_pos)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        \n",
    "            if i % 300 == 0:\n",
    "                log.info('Epoch : {}/{}, Batch : {}/{}, Loss : {:.3f}, ACC : {:.3f}, AUC : {:.3f}'.format(epoch+1, num_epochs, i+1, len(train_dataloader), batch_mean_loss, batch_acc, auc))\n",
    "        log.info('Train Evaluation Result')\n",
    "        log.info('Epoch : {}/{}, Batch : {}/{}, Loss : {:.3f}, ACC : {:.3f}, AUC:{:.3f}'.format(epoch+1, num_epochs, i+1, len(train_dataloader), batch_mean_loss, batch_acc, auc))\n",
    "    \n",
    "        number = []\n",
    "        for i in range(len(ID)):\n",
    "            number += [(train_ID == ID[i]).sum()]\n",
    "        total = {'ID' : ID, 'long_short' : long_short, 'prob' : train_pos, 'pred_label' : label}    \n",
    "    \n",
    "        prob_mean = []\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for i in range(len(np.unique(np.array(ID)))):\n",
    "            index = np.array(total['ID']) == np.unique(np.array(ID))[i]\n",
    "            prob_mean += [np.array(total['prob'])[index].sum() / index.sum()]\n",
    "            y_true += [np.array(total['long_short'])[index][0]]\n",
    "            y_pred += [np.array(total['pred_label'])[index][0]]\n",
    "        \n",
    "        acc = metrics.accuracy_score(y_true, y_pred)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_true, prob_mean)\n",
    "        auc = metrics.auc(fpr, tpr)    \n",
    "    \n",
    "    \n",
    "        log.info('Train_Patient_Level_ACC : {:.3f} / Train_Patient_Level_AUC : {:.3f}'.format(acc, auc))    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        test_loss = []\n",
    "        test_predicted = []\n",
    "        test_label = []\n",
    "        test_pos = []\n",
    "        ID = []\n",
    "        patch_ID = []\n",
    "        long_short = []    \n",
    "        label = []\n",
    "             \n",
    "        model.eval()\n",
    "        for i, batch in enumerate(test_dataloader):\n",
    "            output_ = model(batch['image'].to(device))\n",
    "            loss_ = criterion(output_, batch['long_short'].to(device))\n",
    "        \n",
    "            #evaluation result\n",
    "            pred_label = np.argmax(output_.cpu().detach().numpy(), 1)\n",
    "            pred_prob  = nn.Softmax(1)(output_).cpu().detach().numpy()\n",
    "            positive_prob = pred_prob[:, 1].tolist()\n",
    "                \n",
    "                \n",
    "            test_label += batch['long_short'].tolist()   \n",
    "            test_loss += [loss_.tolist()]\n",
    "            test_predicted += pred_label.tolist()\n",
    "            test_pos += positive_prob\n",
    "            label += pred_label.tolist()\n",
    "        \n",
    "        \n",
    "            test_patient = []\n",
    "            for i in range(len(batch['ID'])):\n",
    "                test_patient.append(batch['ID'][i][:12])\n",
    "                \n",
    "            test_patient_patch = []\n",
    "            for i in range(len(batch['ID'])):\n",
    "                test_patient_patch.append(batch['ID'][i])\n",
    "                \n",
    "            \n",
    "                \n",
    "                \n",
    "            ID += test_patient\n",
    "            patch_ID += test_patient_patch\n",
    "            duration = batch['duration'].tolist()\n",
    "\n",
    "            long_short += batch['long_short'].tolist()\n",
    "        \n",
    "            batch_acc = np.sum(np.array(test_label) ==  np.array(test_predicted))/ len(test_label)\n",
    "            batch_mean_loss = sum(test_loss) / len(test_loss)\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(test_label, test_pos)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "        total = {'ID' : ID, 'patch_ID' : patch_ID, 'long_short' : long_short, 'duration' : duration, 'prob' : test_pos, 'pred_label' : label}\n",
    "        \n",
    "        log.info('TEST Evaluation Result')\n",
    "        log.info('Epoch : {}/{}, Batch : {}/{}, Loss : {:.3f}, ACC : {:.3f}, AUC : {:.3f}'.format(epoch+1, num_epochs, i+1, len(test_dataloader), batch_mean_loss, batch_acc, auc))    \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "     \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # 데이터 프레임 형성(환자별)\n",
    "        ID_ = []\n",
    "        patch_ = []\n",
    "        prob_mean = []\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        #duration = []\n",
    "        for i in range(len(np.unique(np.array(patch_ID)))):\n",
    "            index = np.array(total['patch_ID']) == np.unique(np.array(patch_ID))[i]\n",
    "            ID_ += np.array(total['ID'])[index].tolist()\n",
    "            patch_ += np.array(total['patch_ID'])[index].tolist()\n",
    "            prob_mean += np.array(total['prob'])[index].tolist()\n",
    "            y_true += np.array(total['long_short'])[index].tolist()    \n",
    "            y_pred += np.array(total['pred_label'])[index].tolist()\n",
    "            #duration += np.array(total['duration'])[index].tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "        DataFrame_Patient_Level = pd.DataFrame({'ID' : np.array(ID_), 'patch_ID' : np.array(patch_), 'prob' : np.array(prob_mean), \n",
    "                                                'true_label' : np.array(y_true), 'pred_label' :np.array(y_pred)})\n",
    "    \n",
    "        DataFrame_Patient_Level_groupby = DataFrame_Patient_Level.groupby('ID').mean()\n",
    "        DataFrame_Patient_Level_groupby_patch = DataFrame_Patient_Level.groupby('patch_ID').mean()\n",
    "                                  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ### 데이터 프레임 형성(patch별  ->  환자별)\n",
    "        \n",
    "        patchID = []\n",
    "        for i in range(len(DataFrame_Patient_Level_groupby_patch.index.values)):\n",
    "            patchID.append(DataFrame_Patient_Level_groupby_patch.index.values[i][:12])\n",
    "        patchID = np.array(patchID)\n",
    "    \n",
    "        final_ID = []\n",
    "        final_mean_prob = []\n",
    "        final_max_prob = []\n",
    "        final_min_prob = []\n",
    "        final_true_label = []\n",
    "        # final_pred_label = []\n",
    "        for i in range(len(np.unique(np.array(ID)))):\n",
    "    \n",
    "            patient_index = (patchID == np.unique(np.array(ID))[i])  # patchID : patch ID ,  np.unique(ID) : patient ID\n",
    "            mean_prob = np.mean(DataFrame_Patient_Level_groupby_patch[patient_index]['prob'].values)\n",
    "            max_prob = np.max(DataFrame_Patient_Level_groupby_patch[patient_index]['prob'].values)\n",
    "            min_prob = np.min(DataFrame_Patient_Level_groupby_patch[patient_index]['prob'].values)\n",
    "            true_label = DataFrame_Patient_Level_groupby_patch[patient_index]['true_label'].values[0]\n",
    "            # pred_label = DataFrame_Patient_Level_groupby_patch[patient_index]['pred_label'].values[0]\n",
    "    \n",
    "            final_ID += [np.unique(np.array(ID))[i]]\n",
    "            final_mean_prob += [mean_prob]\n",
    "            final_max_prob += [max_prob]\n",
    "            final_min_prob += [min_prob]\n",
    "            final_true_label += [true_label]\n",
    "            \n",
    "    \n",
    "        final_df = {'ID' : final_ID, 'mean_prob' : final_mean_prob, 'max_prob' : final_max_prob, \n",
    "                    'min_prob' : final_min_prob, 'true_label' : final_true_label}\n",
    "        \n",
    "        \n",
    "        fpr, tpr, thresholds = metrics.roc_curve(final_df['true_label'], final_df['mean_prob'])\n",
    "        mean_auc = metrics.auc(fpr, tpr)  \n",
    "        \n",
    "        fpr, tpr, thresholds = metrics.roc_curve(final_df['true_label'], final_df['max_prob'])\n",
    "        max_auc = metrics.auc(fpr, tpr)  \n",
    "        \n",
    "        fpr, tpr, thresholds = metrics.roc_curve(final_df['true_label'], final_df['min_prob'])\n",
    "        min_auc = metrics.auc(fpr, tpr)  \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        create_file(f'checkpoint/{info}/result.csv', f'epoch{epoch+1}')\n",
    "    \n",
    "        log.info('\\n')\n",
    "        # log.info('---------------------------------  Test_Patient_Level_AUC : {:.3f}'.format(auc))\n",
    "        log.info('---------------------------------   Test_Patient_Level_Mean_AUC : {:.3f}'.format(mean_auc))\n",
    "        log.info('---------------------------------  Test_Patient_Level_Max_AUC : {:.3f}'.format(max_auc))\n",
    "        log.info('---------------------------------   Test_Patient_Level_Min_AUC : {:.3f}'.format(min_auc))\n",
    "        log.info('\\n')\n",
    "\n",
    "        \n",
    "        \n",
    "        #duration_csv = []\n",
    "        #for i in range(len(final_df['ID'])):\n",
    "        #    duration_csv.append(DataFrame_Patient_Level[DataFrame_Patient_Level['ID'].values  == final_df['ID'][i]]['duration'].values[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        csv_file = np.hstack([np.array(final_df['ID']).reshape(-1, 1), \n",
    "                              np.array(final_df['mean_prob']).reshape(-1, 1), \n",
    "                              np.array(final_df['max_prob']).reshape(-1, 1), \n",
    "                              np.array(final_df['min_prob']).reshape(-1, 1),\n",
    "                              np.array(final_df['true_label']).reshape(-1, 1),\n",
    "                              #np.repeat(true_label, repeats=len(final_ID)).reshape(-1, 1),\n",
    "                              np.repeat(mean_auc, repeats=len(final_ID)).reshape(-1, 1),\n",
    "                              np.repeat(max_auc, repeats=len(final_ID)).reshape(-1, 1),\n",
    "                              np.repeat(min_auc, repeats=len(final_ID)).reshape(-1, 1)])\n",
    "        \n",
    "        create_file(f'checkpoint/{info}/result.csv', 'ID, mean_prob, max_prob, min_prob, true_label, mean_auc, max_auc, min_auc')\n",
    "\n",
    "\n",
    "        for i in range(len(csv_file)):\n",
    "            create_file(f'checkpoint/{info}/result.csv', ','.join(csv_file[i]))\n",
    "        \n",
    "        \n",
    "        torch.save(model.state_dict(), 'checkpoint/{}/fold {} epoch {}.pth'.format(info, fold+1, epoch+1))\n",
    "    create_file(f'checkpoint/{info}/result.csv', '--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-AA-3488</td>\n",
       "      <td>0.5956802566846212</td>\n",
       "      <td>0.6300025880336761</td>\n",
       "      <td>0.5541651546955109</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-AA-3529</td>\n",
       "      <td>0.6210820376873016</td>\n",
       "      <td>0.6389541923999786</td>\n",
       "      <td>0.6032098829746246</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-AA-3660</td>\n",
       "      <td>0.6377338171005249</td>\n",
       "      <td>0.6377338171005249</td>\n",
       "      <td>0.6377338171005249</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-AA-3845</td>\n",
       "      <td>0.5753026008605957</td>\n",
       "      <td>0.5753026008605957</td>\n",
       "      <td>0.5753026008605957</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-AA-A01D</td>\n",
       "      <td>0.6186747948328654</td>\n",
       "      <td>0.6394073367118835</td>\n",
       "      <td>0.5846368968486786</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TCGA-AA-A02H</td>\n",
       "      <td>0.6300164759159088</td>\n",
       "      <td>0.6300164759159088</td>\n",
       "      <td>0.6300164759159088</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TCGA-AA-A03F</td>\n",
       "      <td>0.632108211517334</td>\n",
       "      <td>0.632108211517334</td>\n",
       "      <td>0.632108211517334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TCGA-AF-5654</td>\n",
       "      <td>0.5884408056735992</td>\n",
       "      <td>0.5976093411445618</td>\n",
       "      <td>0.5791580677032471</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TCGA-AF-A56L</td>\n",
       "      <td>0.5800895988941193</td>\n",
       "      <td>0.5912765860557556</td>\n",
       "      <td>0.5689026117324829</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TCGA-AG-A023</td>\n",
       "      <td>0.6356629133224487</td>\n",
       "      <td>0.6356629133224487</td>\n",
       "      <td>0.6356629133224487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TCGA-AG-A02N</td>\n",
       "      <td>0.5892184793949127</td>\n",
       "      <td>0.6153274178504944</td>\n",
       "      <td>0.5585779249668121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TCGA-AZ-4682</td>\n",
       "      <td>0.603771448135376</td>\n",
       "      <td>0.603771448135376</td>\n",
       "      <td>0.603771448135376</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TCGA-AZ-6598</td>\n",
       "      <td>0.6222735643386841</td>\n",
       "      <td>0.6222735643386841</td>\n",
       "      <td>0.6222735643386841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TCGA-AZ-6601</td>\n",
       "      <td>0.5433929562568665</td>\n",
       "      <td>0.5433929562568665</td>\n",
       "      <td>0.5433929562568665</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TCGA-CL-4957</td>\n",
       "      <td>0.5851560235023499</td>\n",
       "      <td>0.6060468852519989</td>\n",
       "      <td>0.5642558336257935</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TCGA-DM-A1D9</td>\n",
       "      <td>0.5344944298267365</td>\n",
       "      <td>0.5344944298267365</td>\n",
       "      <td>0.5344944298267365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TCGA-DM-A1DA</td>\n",
       "      <td>0.6177063286304474</td>\n",
       "      <td>0.6177063286304474</td>\n",
       "      <td>0.6177063286304474</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TCGA-DM-A1HA</td>\n",
       "      <td>0.5860801935195923</td>\n",
       "      <td>0.5860801935195923</td>\n",
       "      <td>0.5860801935195923</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TCGA-DY-A1DF</td>\n",
       "      <td>0.6273411065340042</td>\n",
       "      <td>0.6307945549488068</td>\n",
       "      <td>0.6238876581192017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24358974358974356</td>\n",
       "      <td>0.21794871794871792</td>\n",
       "      <td>0.26923076923076916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                   1                   2                   3  \\\n",
       "0   TCGA-AA-3488  0.5956802566846212  0.6300025880336761  0.5541651546955109   \n",
       "1   TCGA-AA-3529  0.6210820376873016  0.6389541923999786  0.6032098829746246   \n",
       "2   TCGA-AA-3660  0.6377338171005249  0.6377338171005249  0.6377338171005249   \n",
       "3   TCGA-AA-3845  0.5753026008605957  0.5753026008605957  0.5753026008605957   \n",
       "4   TCGA-AA-A01D  0.6186747948328654  0.6394073367118835  0.5846368968486786   \n",
       "5   TCGA-AA-A02H  0.6300164759159088  0.6300164759159088  0.6300164759159088   \n",
       "6   TCGA-AA-A03F   0.632108211517334   0.632108211517334   0.632108211517334   \n",
       "7   TCGA-AF-5654  0.5884408056735992  0.5976093411445618  0.5791580677032471   \n",
       "8   TCGA-AF-A56L  0.5800895988941193  0.5912765860557556  0.5689026117324829   \n",
       "9   TCGA-AG-A023  0.6356629133224487  0.6356629133224487  0.6356629133224487   \n",
       "10  TCGA-AG-A02N  0.5892184793949127  0.6153274178504944  0.5585779249668121   \n",
       "11  TCGA-AZ-4682   0.603771448135376   0.603771448135376   0.603771448135376   \n",
       "12  TCGA-AZ-6598  0.6222735643386841  0.6222735643386841  0.6222735643386841   \n",
       "13  TCGA-AZ-6601  0.5433929562568665  0.5433929562568665  0.5433929562568665   \n",
       "14  TCGA-CL-4957  0.5851560235023499  0.6060468852519989  0.5642558336257935   \n",
       "15  TCGA-DM-A1D9  0.5344944298267365  0.5344944298267365  0.5344944298267365   \n",
       "16  TCGA-DM-A1DA  0.6177063286304474  0.6177063286304474  0.6177063286304474   \n",
       "17  TCGA-DM-A1HA  0.5860801935195923  0.5860801935195923  0.5860801935195923   \n",
       "18  TCGA-DY-A1DF  0.6273411065340042  0.6307945549488068  0.6238876581192017   \n",
       "\n",
       "    4                    5                    6                    7  \n",
       "0   0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "1   0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "2   1  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "3   0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "4   0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "5   0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "6   0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "7   0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "8   1  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "9   0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "10  1  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "11  0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "12  0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "13  1  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "14  0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "15  1  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "16  0  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "17  1  0.24358974358974356  0.21794871794871792  0.26923076923076916  \n",
       "18  0  0.24358974358974356  0.21794871794871792  0.26923076923076916  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
